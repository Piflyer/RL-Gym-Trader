{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Gymnasium to do simple trading algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gymnasium \n",
    "!pip install yfinance\n",
    "!pip install \"stable-baselines3[extra]>=2.0.0a4\"\n",
    "!pip install ipywidgets\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install torch\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, stock='AAPL', minbuy=10, gran='1d', period='max', shares=3, boughtat=\"2023-12-01\", randomize=True, seed=0, verbose=False):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.running_mean = 0\n",
    "        self.running_std = 1  \n",
    "        self.decay_factor = 0.99  \n",
    "        self.epsilon = 1e-7  \n",
    "        \n",
    "        self.stock = stock\n",
    "        self.minbuy = minbuy\n",
    "        self.gran = gran\n",
    "        self.period = period\n",
    "        self.shares = shares\n",
    "        self.boughtat = boughtat\n",
    "        self.seed = seed\n",
    "        self.randomize = randomize\n",
    "        self.max_networth = 0\n",
    "        self.print = verbose\n",
    "        self.streak = 0\n",
    "        self.is_init = True\n",
    "        \n",
    "        if self.gran in ['5m', '15m', '30m']:\n",
    "            print(\"[WARNING] Data granularity can only go back to 60 Days Maxiumum\")\n",
    "        if self.gran in ['1h', '60m']:\n",
    "            print(\"[WARNING] Data granularity can only go back to 730 Days Maxiumum\")\n",
    "        self.random_symbols = [\n",
    "            \"NVDA\" , \"AMZN\", \"GOOGL\", \"MSFT\", \"AAPL\", \"META\", \"NVDA\", \"ADBE\", \"NFLX\", \"NANC\", \"KRUZ\", \"VOO\", \"FTEC\", \"TSLA\"\n",
    "        ]\n",
    "        self.random_gran_period_pairs = {\n",
    "            '1d' : ['max']\n",
    "        }\n",
    "        if self.randomize:\n",
    "            self._randomize()\n",
    "        else:\n",
    "            self.data = yf.Ticker(self.stock).history(period=self.period, interval=self.gran, auto_adjust=True)\n",
    "        \n",
    "        self._init_obs()\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(1, 48), dtype=np.float32\n",
    "        )\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.networth_rewd = 0\n",
    "        \n",
    "    def _init_obs(self):\n",
    "        self.current_day = self.boughtat\n",
    "        self.cur_indx = self.data.index.get_loc(self.current_day)\n",
    "        self.init_networth = self.shares * self.data.loc[self.boughtat, 'Close']\n",
    "        self.networth = self.init_networth\n",
    "        self.previous_open_close = self.data.loc[self.boughtat, 'Open'], self.data.loc[self.boughtat, 'Close']\n",
    "        self.previous_high_low = self.data.loc[self.boughtat, 'High'], self.data.loc[self.boughtat, 'Low']\n",
    "        self.previous_volume = self.data.loc[self.boughtat, 'Volume']\n",
    "        self.previous_momentum_wk = self._calculate_momentum(7)\n",
    "        self.previous_momentum_mon = self._calculate_momentum(30)\n",
    "        self.previous_wk_close = np.zeros((1,7))\n",
    "        self.previous_mo_close = np.zeros((1,30))\n",
    "        self.bought_price = self.data.loc[self.boughtat, 'Close']\n",
    "        self.current_shares = self.shares\n",
    "        self.relneworth = 0\n",
    "        self.current_action = 0\n",
    "        self.max_networth = 0\n",
    "        self.streak = 0\n",
    "        self.is_init = True\n",
    "\n",
    "        self.has_position = True\n",
    "        self.previous_obs = np.zeros((1, 48)).astype(np.float32)\n",
    "        \n",
    "        \n",
    "    def _randomize(self):\n",
    "        self.random_seed = np.random.randint(0, 100)\n",
    "        np.random.seed(self.random_seed)\n",
    "        # Randomly select number of shares from 1 to 10\n",
    "        self.shares = np.random.randint(1, 10)\n",
    "        \n",
    "        # Randomly select granularity and period\n",
    "        while True:\n",
    "            self.gran = np.random.choice(list(self.random_gran_period_pairs.keys()))\n",
    "            self.period = np.random.choice(self.random_gran_period_pairs[self.gran])\n",
    "            \n",
    "            # Randomly select a stock\n",
    "            self.stock = np.random.choice(self.random_symbols)\n",
    "            \n",
    "            try:\n",
    "                # Fetch data for the randomized stock, period, and granularity\n",
    "                self.data = yf.Ticker(self.stock).history(period=self.period, interval=self.gran, auto_adjust=True)\n",
    "                self.boughtat = np.random.choice(self.data.index[31:])\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    def reset(self, seed=0):\n",
    "        super(TradingEnv, self).reset()\n",
    "        if self.randomize:\n",
    "            self._randomize()\n",
    "        else:\n",
    "            self.data = yf.Ticker(self.stock).history(period=self.period, interval=self.gran, auto_adjust=True)\n",
    "        self.seed = seed\n",
    "        self._init_obs()\n",
    "        info = {\n",
    "            \"init_networth\": self.init_networth,\n",
    "            \"current_networth\": self.networth,\n",
    "            \"current_action\": self.current_action,\n",
    "            \"current_gain\": self.relneworth,\n",
    "            \"diff\": self.networth - self.init_networth,\n",
    "            \n",
    "        }\n",
    "        return self.previous_obs, info\n",
    "    \n",
    "    def _calculate_momentum(self, interval):\n",
    "        if self.cur_indx - interval < 0:\n",
    "            return 0  # Avoid accessing invalid index\n",
    "        past_price = self.data.iloc[self.cur_indx - interval]['Close']\n",
    "        current_price = self.data.iloc[self.cur_indx]['Close']\n",
    "        return (current_price - past_price) / past_price\n",
    "\n",
    "    \n",
    "    def _get_previous_close(self, interval):\n",
    "        return self.data.loc[self.data.index[self.cur_indx-interval:self.cur_indx], 'Close'].to_numpy().reshape(1, interval)\n",
    "    \n",
    "    def step(self, action):\n",
    "        if action == 1:\n",
    "            if self.has_position:\n",
    "                self.relneworth = self.current_shares * (self.previous_open_close[1] - self.bought_price)\n",
    "                self.has_position = False\n",
    "                self.networth += self.relneworth\n",
    "            else:\n",
    "                self.has_position = True\n",
    "                self.relneworth = 0\n",
    "            self.streak = 0\n",
    "            self.bought_price = self.previous_open_close[1]\n",
    "            self.current_action = 1\n",
    "            self.max_networth = 0\n",
    "        else:\n",
    "            self.streak += 1\n",
    "            self.current_action = 0\n",
    "            self.relneworth = self.shares * (self.previous_open_close[1] - self.bought_price)\n",
    "            if self.relneworth > self.max_networth:\n",
    "                self.max_networth = self.relneworth\n",
    "            \n",
    "        self.cur_indx += 1\n",
    "        info = {\n",
    "            \"init_networth\": self.init_networth,\n",
    "            \"current_networth\": self.networth,\n",
    "            \"current_action\": self.current_action,\n",
    "            \"current_gain\": self.relneworth,\n",
    "            \"diff\": self.networth - self.init_networth,\n",
    "            \n",
    "        }\n",
    "        try:\n",
    "            self.current_day = self.data.index[self.cur_indx]\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "        except IndexError:\n",
    "            print(\"[INFO] Data Exhausted\")\n",
    "            self.current_day = self.data.index[-1]\n",
    "            terminated = False\n",
    "            truncated = True\n",
    "            return (\n",
    "                self.prev_obs,\n",
    "                self._reward(action),\n",
    "                True,\n",
    "                True,\n",
    "                info\n",
    "            )\n",
    "\n",
    "        self.previous_open_close = np.array([self.data.loc[self.current_day, 'Open'], self.data.loc[self.current_day, 'Close']])\n",
    "        self.previous_high_low = np.array([self.data.loc[self.current_day, 'High'], self.data.loc[self.current_day, 'Low']])\n",
    "        self.previous_volume = np.array([self.data.loc[self.current_day, 'Volume']])\n",
    "        self.previous_momentum_wk = self._calculate_momentum(7)\n",
    "        self.previous_momentum_mon = self._calculate_momentum(30)\n",
    "        self.previous_wk_close = self.data.loc[self.data.index[self.cur_indx-7:self.cur_indx], 'Close'].to_numpy()\n",
    "        self.previous_mo_close = self.data.loc[self.data.index[self.cur_indx-30:self.cur_indx], 'Close'].to_numpy()\n",
    "\n",
    "        # Flatten and construct the observation array\n",
    "        observation = np.concatenate([\n",
    "            self.previous_open_close.flatten(), # 2\n",
    "            self.previous_high_low.flatten(), # 2\n",
    "            self.previous_volume.flatten(), # 1\n",
    "            self.previous_wk_close.flatten(), # 7\n",
    "            self.previous_mo_close.flatten(), # 30\n",
    "            np.array([\n",
    "                self.previous_momentum_wk, # 1\n",
    "                self.previous_momentum_mon, # 1\n",
    "                self.bought_price, # 1\n",
    "                self.current_shares, # 1\n",
    "                self.relneworth, # 1\n",
    "                self.current_action # 1\n",
    "            ])\n",
    "        ]).astype(np.float32)\n",
    "        \n",
    "        observation = observation.reshape(1, -1)\n",
    "        self.prev_obs = observation\n",
    "\n",
    "        # Termination terms\n",
    "        if self.networth < (self.init_networth * 0.90):\n",
    "            # print(\"[INFO] Terminated due to Loss\")\n",
    "            terminated = True\n",
    "        truncated = False\n",
    "        if self.cur_indx >= len(self.data.index) - 1:\n",
    "            truncated = True\n",
    "\n",
    "\n",
    "        # Reward\n",
    "        reward = self._reward(action)\n",
    "        \n",
    "        self.is_init = False\n",
    "\n",
    "        # Additional Info\n",
    "        if self.print:\n",
    "            print(\" \")\n",
    "            print(\"---------------------------------------------------------\")\n",
    "            print(f\"[INFO] Current Stock: {self.stock}\")\n",
    "            print(f\"[INFO] Current Day: {self.current_day}\")\n",
    "            print(f\"[INFO] Current Open: {self.previous_open_close[0]}\")\n",
    "            print(f\"[INFO] Current Net Worth: {self.networth}\")\n",
    "            print(f\"[INFO] Holding Share: {self.has_position}\")\n",
    "            print(f\"[INFO] Current Share Net Worth: {self.relneworth}\")\n",
    "            print(\"[INFO] Current Action: \" + (\"Hold\" if self.current_action == 0 else \"Sell\" if self.current_action == 1 and not self.has_position else \"Buy\"))\n",
    "            print(\"---------------------------------------------------------\")\n",
    "\n",
    "        return (\n",
    "            observation,\n",
    "            reward,\n",
    "            terminated,\n",
    "            truncated,\n",
    "            info\n",
    "        )\n",
    "    def _reward(self, action):\n",
    "        reward_weights = {\n",
    "            \"relnetworth\": 0.7,\n",
    "            \"streak\": 0.3,\n",
    "            \n",
    "        }\n",
    "        \n",
    "        self.networth_rewd, self.streak_rewd = 0, 0\n",
    "        \n",
    "        # self.networth_rewd = self.relneworth\n",
    "        if self.has_position:\n",
    "            if self.relneworth < self.max_networth and self.max_networth > 0:\n",
    "                self.networth_rewd = (self.relneworth - self.max_networth)/self.max_networth\n",
    "            else:\n",
    "                self.networth_rewd = self.relneworth / self.bought_price\n",
    "        else:\n",
    "            self.networth_rewd = (self.relneworth / self.bought_price) * -1\n",
    "        \n",
    "        if (self.streak < self.minbuy and not self.is_init) and action == 1:\n",
    "            self.streak_rewd = -10\n",
    "        else:\n",
    "            self.streak_rewd = 2\n",
    "        \n",
    "        # Optionally clip the normalized reward to avoid very large values\n",
    "        reward_min = -7\n",
    "        reward_max = 7\n",
    "        \n",
    "        normalized_reward = reward_weights[\"relnetworth\"] * self.networth_rewd + reward_weights[\"streak\"] * self.streak_rewd\n",
    "        normalized_reward = np.clip(normalized_reward, reward_min, reward_max)\n",
    "        \n",
    "        return normalized_reward\n",
    "    \n",
    "    def render(self):\n",
    "        # Graph out the stock price with the buy and sell points\n",
    "        pass\n",
    "    \n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Stock test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TradingEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mTradingEnv\u001b[49m(stock\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m, minbuy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, gran\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1d\u001b[39m\u001b[38;5;124m\"\u001b[39m, period\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, shares\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, boughtat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2025-01-21\u001b[39m\u001b[38;5;124m\"\u001b[39m, randomize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TradingEnv' is not defined"
     ]
    }
   ],
   "source": [
    "env = TradingEnv(stock=\"AAPL\", minbuy=10, gran=\"1d\", period=\"max\", shares=3, boughtat=\"2025-01-21\", randomize=False, seed=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-01-22 00:00:00-05:00\n",
      "[INFO] Current Open: 219.54859611049605\n",
      "[INFO] Current Net Worth: 667.1864318847656\n",
      "[INFO] Holding Share: True\n",
      "[INFO] Current Share Net Worth: 0.0\n",
      "[INFO] Current Action: Hold\n",
      "---------------------------------------------------------\n",
      "\n",
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-01-23 00:00:00-05:00\n",
      "[INFO] Current Open: 224.493183388126\n",
      "[INFO] Current Net Worth: 667.1864318847656\n",
      "[INFO] Holding Share: True\n",
      "[INFO] Current Share Net Worth: 3.566070556640625\n",
      "[INFO] Current Action: Hold\n",
      "---------------------------------------------------------\n",
      "\n",
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-01-24 00:00:00-05:00\n",
      "[INFO] Current Open: 224.53312753788666\n",
      "[INFO] Current Net Worth: 667.1864318847656\n",
      "[INFO] Holding Share: True\n",
      "[INFO] Current Share Net Worth: 3.056671142578125\n",
      "[INFO] Current Action: Hold\n",
      "---------------------------------------------------------\n",
      "\n",
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-01-27 00:00:00-05:00\n",
      "[INFO] Current Open: 223.77396171163917\n",
      "[INFO] Current Net Worth: 667.1864318847656\n",
      "[INFO] Holding Share: True\n",
      "[INFO] Current Share Net Worth: 0.4195404052734375\n",
      "[INFO] Current Action: Hold\n",
      "---------------------------------------------------------\n",
      "\n",
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-01-28 00:00:00-05:00\n",
      "[INFO] Current Open: 230.59647127201654\n",
      "[INFO] Current Net Worth: 688.8226318359375\n",
      "[INFO] Holding Share: False\n",
      "[INFO] Current Share Net Worth: 21.636199951171875\n",
      "[INFO] Current Action: Sell\n",
      "---------------------------------------------------------\n",
      "\n",
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-01-29 00:00:00-05:00\n",
      "[INFO] Current Open: 233.86287156365174\n",
      "[INFO] Current Net Worth: 688.8226318359375\n",
      "[INFO] Holding Share: True\n",
      "[INFO] Current Share Net Worth: 0\n",
      "[INFO] Current Action: Buy\n",
      "---------------------------------------------------------\n",
      "\n",
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-01-30 00:00:00-05:00\n",
      "[INFO] Current Open: 238.40787147181928\n",
      "[INFO] Current Net Worth: 688.8226318359375\n",
      "[INFO] Holding Share: True\n",
      "[INFO] Current Share Net Worth: 3.2964019775390625\n",
      "[INFO] Current Action: Hold\n",
      "---------------------------------------------------------\n",
      "\n",
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-01-31 00:00:00-05:00\n",
      "[INFO] Current Open: 246.91852728753366\n",
      "[INFO] Current Net Worth: 686.8148345947266\n",
      "[INFO] Holding Share: False\n",
      "[INFO] Current Share Net Worth: -2.0077972412109375\n",
      "[INFO] Current Action: Sell\n",
      "---------------------------------------------------------\n",
      "\n",
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-02-03 00:00:00-05:00\n",
      "[INFO] Current Open: 229.73741895869952\n",
      "[INFO] Current Net Worth: 686.8148345947266\n",
      "[INFO] Holding Share: False\n",
      "[INFO] Current Share Net Worth: -4.7647247314453125\n",
      "[INFO] Current Action: Hold\n",
      "---------------------------------------------------------\n",
      "\n",
      " \n",
      "---------------------------------------------------------\n",
      "[INFO] Current Stock: AAPL\n",
      "[INFO] Current Day: 2025-02-04 00:00:00-05:00\n",
      "[INFO] Current Open: 227.00041910872287\n",
      "[INFO] Current Net Worth: 686.8148345947266\n",
      "[INFO] Holding Share: True\n",
      "[INFO] Current Share Net Worth: 0\n",
      "[INFO] Current Action: Buy\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the environment for 10 steps\n",
    "obs = env.reset()\n",
    "for _ in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    print()\n",
    "    if terminated or truncated:\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tim/mambaforge/envs/mujoco/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 10000`, after every 156 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=1000 and n_envs=10)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddd437029314247aa3107d988998ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec_env = make_vec_env(TradingEnv, n_envs=10)\n",
    "learning_rate = 3e-4  # Increase from the default 2.5e-4\n",
    "ent_coef = 0.02  # Default: 0.0 (increase to encourage exploration)\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1, device=\"cpu\", n_steps=1000, learning_rate=learning_rate, ent_coef=ent_coef)\n",
    "model.learn(total_timesteps=10000, progress_bar=True, tb_log_name=\"stock_ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(50):\n",
    "    print(f\"Epoch {k+1}\")\n",
    "    obs = vec_env.reset()\n",
    "    total_rewards = np.zeros(6)\n",
    "    for i in tqdm(range(1000)):\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, rewards, done, info = vec_env.step(action)\n",
    "        total_rewards = np.add(total_rewards, rewards)\n",
    "    # Get average reward over the 12 environments\n",
    "    print(f\"Average reward: {np.mean(total_rewards) / 1000}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m netgains \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[1;32m      6\u001b[0m     obs, rewards, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReward \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrewards\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "env = make_vec_env(TradingEnv, n_envs=1, env_kwargs={\"randomize\": False, \"verbose\": True, \"stock\": \"AAPL\", \"shares\": 3, \"boughtat\": \"2023-11-13\"})\n",
    "obs = env.reset()\n",
    "netgains = 0\n",
    "for j in range(300):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    print(f\"Reward {rewards}\")\n",
    "    if done:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
